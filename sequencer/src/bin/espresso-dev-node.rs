use std::time::Duration;

use async_compatibility_layer::logging::{setup_backtrace, setup_logging};
use async_std::task::sleep;
use clap::Parser;
use futures::FutureExt;
use sequencer::{api::options, api::test_helpers::TestNetwork, persistence, testing::TestConfig};
use sequencer_utils::{
    deployer::{deploy, Contracts},
    AnvilOptions,
};
use url::Url;

#[derive(Clone, Debug, Parser)]
struct Args {
    /// A JSON-RPC endpoint for the L1 to deploy to. If this is not provided, an Avil node will be
    /// launched automatically.
    #[clap(short, long, env = "ESPRESSO_SEQUENCER_L1_PROVIDER")]
    rpc_url: Option<Url>,
    /// Mnemonic for an L1 wallet.
    ///
    /// This wallet is used to deploy the contracts, so the account indicated by ACCOUNT_INDEX must
    /// be funded with with ETH.
    #[clap(
        long,
        name = "MNEMONIC",
        env = "ESPRESSO_SEQUENCER_ETH_MNEMONIC",
        default_value = "test test test test test test test test test test test junk"
    )]
    mnemonic: String,
    /// Account index in the L1 wallet generated by MNEMONIC to use when deploying the contracts.
    #[clap(
        long,
        name = "ACCOUNT_INDEX",
        env = "ESPRESSO_DEPLOYER_ACCOUNT_INDEX",
        default_value = "0"
    )]
    account_index: u32,

    /// Port that the HTTP API will use.
    #[clap(long, env = "ESPRESSO_SEQUENCER_API_PORT")]
    sequencer_api_port: u16,

    /// Maximum concurrent connections allowed by the HTTP API server.
    #[clap(long, env = "ESPRESSO_SEQUENCER_MAX_CONNECTIONS")]
    sequencer_api_max_connections: Option<usize>,

    /// Port for connecting to the builder.
    #[clap(short, long, env = "ESPRESSO_BUILDER_PORT")]
    builder_port: Option<u16>,

    #[clap(flatten)]
    sql: persistence::sql::Options,
}

#[async_std::main]
async fn main() -> anyhow::Result<()> {
    setup_logging();
    setup_backtrace();

    let cli_params = Args::parse();
    let api_options = options::Options::from(options::Http {
        port: cli_params.sequencer_api_port,
        max_connections: cli_params.sequencer_api_max_connections,
    })
    .status(Default::default())
    .state(Default::default())
    .submit(Default::default())
    .query_sql(Default::default(), cli_params.sql);

    let (url, _anvil) = if let Some(url) = cli_params.rpc_url {
        (url, None)
    } else {
        tracing::warn!("L1 url is not provided. running an anvil node");
        let instance = AnvilOptions::default().spawn().await;
        let url = instance.url();
        tracing::info!("l1 url: {}", url);
        (url, Some(instance))
    };

    let network = TestNetwork::new(
        api_options,
        [persistence::no_storage::Options; TestConfig::NUM_NODES],
        url.clone(),
        cli_params.builder_port,
    )
    .await;

    let config = network.cfg.hotshot_config();
    tracing::info!("Hotshot config {config:?}");

    let contracts = Contracts::new();

    tracing::info!("deploying the contracts");

    let light_client_genesis = network.light_client_genesis();

    let _contracts = deploy(
        url.clone(),
        cli_params.mnemonic.clone(),
        cli_params.account_index,
        true,
        None,
        async { Ok(light_client_genesis) }.boxed(),
        contracts,
    )
    .await?;

    loop {
        sleep(Duration::from_secs(3600)).await
    }
}

#[cfg(test)]
mod tests {
    use std::{process::Child, thread::sleep, time::Duration};

    use async_compatibility_layer::logging::{setup_backtrace, setup_logging};
    use async_std::stream::StreamExt;
    use committable::{Commitment, Committable};
    use es_version::SequencerVersion;
    use escargot::CargoBuild;
    use futures::TryStreamExt;
    use hotshot_query_service::{
        availability::{BlockQueryData, TransactionQueryData},
        data_source::sql::testing::TmpDb,
    };
    use jf_merkle_tree::MerkleTreeScheme;
    use portpicker::pick_unused_port;
    use sequencer::{
        api::endpoints::NamespaceProofQueryData, state::BlockMerkleTree, Header, SeqTypes,
        Transaction,
    };
    use surf_disco::Client;
    use tide_disco::error::ServerError;

    pub struct BackgroundProcess(Child);

    impl Drop for BackgroundProcess {
        fn drop(&mut self) {
            self.0.kill().unwrap();
        }
    }

    // If this test failed and you are doing changes on the following stuff, please
    // sync your changes to [`espresso-sequencer-go`](https://github.com/EspressoSystems/espresso-sequencer-go)
    // and open a PR.
    // - APIs update
    // - Types (like `Header`) update
    #[async_std::test]
    async fn dev_node_test() {
        setup_logging();
        setup_backtrace();

        let builder_port = pick_unused_port().unwrap();

        let api_port = pick_unused_port().unwrap();

        let db = TmpDb::init().await;
        let postgres_port = db.port();

        let process = CargoBuild::new()
            .bin("espresso-dev-node")
            .features("testing")
            .current_target()
            .run()
            .unwrap()
            .command()
            .env("ESPRESSO_BUILDER_PORT", builder_port.to_string())
            .env("ESPRESSO_SEQUENCER_API_PORT", api_port.to_string())
            .env("ESPRESSO_SEQUENCER_POSTGRES_HOST", "localhost")
            .env(
                "ESPRESSO_SEQUENCER_POSTGRES_PORT",
                postgres_port.to_string(),
            )
            .env("ESPRESSO_SEQUENCER_POSTGRES_USER", "postgres")
            .env("ESPRESSO_SEQUENCER_POSTGRES_PASSWORD", "password")
            .spawn()
            .unwrap();

        let _process = BackgroundProcess(process);

        let api_client: Client<ServerError, SequencerVersion> =
            Client::new(format!("http://localhost:{api_port}").parse().unwrap());
        api_client.connect(None).await;

        tracing::info!("waiting for blocks");
        let _ = api_client
            .socket("availability/stream/blocks/0")
            .subscribe::<BlockQueryData<SeqTypes>>()
            .await
            .unwrap()
            .take(5)
            .try_collect::<Vec<_>>()
            .await
            .unwrap();

        let builder_api_client: Client<ServerError, SequencerVersion> =
            Client::new(format!("http://localhost:{builder_port}").parse().unwrap());
        builder_api_client.connect(None).await;

        let builder_address = builder_api_client
            .get::<String>("block_info/builderaddress")
            .send()
            .await
            .unwrap();

        assert!(!builder_address.is_empty());

        let tx = Transaction::new(100.into(), vec![1, 2, 3]);

        let hash: Commitment<Transaction> = api_client
            .post("submit/submit")
            .body_json(&tx)
            .unwrap()
            .send()
            .await
            .unwrap();

        let tx_hash = tx.commit();
        assert_eq!(hash, tx_hash);

        while api_client
            .get::<TransactionQueryData<SeqTypes>>(&format!(
                "availability/transaction/hash/{}",
                tx_hash
            ))
            .send()
            .await
            .is_err()
        {
            sleep(Duration::from_secs(3))
        }

        // These endpoints are currently used in `espresso-sequencer-go`. These checks
        // serve as reminders of syncing the API updates to go client repo when they change.
        {
            api_client
                .get::<u64>("status/block-height")
                .send()
                .await
                .unwrap();

            api_client
                .get::<Header>("availability/header/3")
                .send()
                .await
                .unwrap();

            api_client
                .get::<NamespaceProofQueryData>("availability/block/2/namespace/0")
                .send()
                .await
                .unwrap();

            while api_client
                .get::<<BlockMerkleTree as MerkleTreeScheme>::MembershipProof>("block-state/3/2")
                .send()
                .await
                .is_err()
            {
                sleep(Duration::from_secs(3))
            }
        }

        drop(db);
    }
}
